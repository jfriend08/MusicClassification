\documentclass[final]{siamltexmm}

\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\newcommand{\pe}{\psi}
\def\d{\delta}
\def\ds{\displaystyle}
\def\e{{\epsilon}}
\def\eb{\bar{\eta}}
\def\enorm#1{\|#1\|_2}
\def\Fp{F^\prime}
\def\fishpack{{FISHPACK}}
\def\fortran{{FORTRAN}}
\def\gmres{{GMRES}}
\def\gmresm{{\rm GMRES($m$)}}
\def\Kc{{\cal K}}
\def\norm#1{\|#1\|}
\def\wb{{\bar w}}
\def\zb{{\bar z}}

% some definitions of bold math italics to make typing easier.
% They are used in the corollary.

\def\bfE{\mbox{\boldmath$E$}}
\def\bfG{\mbox{\boldmath$G$}}

\title{Music Genre Classification--Base line report}
\author{Hung-Ting Wen\thanks{\tt htw230@nyu.edu}
        \and Yun-shao Sung\thanks{\tt yss265@nyu.edu}}

\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\pagestyle{myheadings}
\thispagestyle{plain}

\section{Baseline approaches}
For baseline approach, first of all, we download the GTZAN data set. It contains 10 different music generes, and 100 of 3 minutes musics in .au format per gerere, which is 1000 songs in toal and about 3GB for its data size. Then SOX was performed for data preprocessing that we sampling each songs with 22050Hz and divided it into 10 clips in .wav, each for 3 seconds. Therefore, each clip will have 66150 values representing music signal intensity within the 3 seconds window.

After data preprocessing, we read each wav file by scipy.io.wavfile and constructed all the clips into python pickle structure, that each keys is the genere, and the value are list of songs, and each song containing list of 10 clips of music signals.

pyfilterbank package was used for mel-frequency bank generation. As trying to reproduce the method of our reference paper, we prepared 12 of the frequency banks covering signal from 0 to 6000 Hz range. Sampling rate for each bank is 22050Hz and they are triangular shaped. As each of the bank serves as a filter purpose that need to convoluted with each song's clip over time domain, numpy.fft.ifft was performed on each bank trying to transform each bank into time domain.

As scattering method need to be convoluted with a lowpass filter at the end, we designed the lowpass filter by scipy.signal.butter for 6500 Hz cutoff frequency, 22050 Hz sampling rate, and in the order of 6. Then scipy.signal.lfilter was performed to filter the signal on frequency domain, which in other word, performing convolution with signal clips on time domain. For the convolution part during scattering, numpy.convolve was performed during eachtime of scattering process.

During scattering process, each clip in a song will produced 1 product at 0-ordered scattering, 12 products with each mel-frequency banks at 1-ordered scattering, and then the summation of 11 to 1 during 2-ordered scattering wich yield 66 products. Therefore, given total 10 clip per song and each clip will produced 79 products during scattering process, each song now will have 790 vectors of scattering-modified clips. As each clip contains 66150 values and this scattered song will genreate huge size of data which is not pratical for any machine with limited memory, therefore we performed energy conversion for each of the clip converting 790 signal vectors into 790 signal values.

The performance for scaterring each of the song is very slow. Each song has to perform 1320 times of convolutions, 790 times of lowpass filtering, and then 790 times of energy conversion. Therefore approxmately each song will need 10 to 15 minutes for scattering process.


\begin{thebibliography}{10}
\bibitem{fpf} {\sc Low pass filter by FFT convolution}, {\em http://www.dsprelated.com/freebooks/sasp/Example\_1\_Low\_Pass\_Filtering.html}
\bibitem{msc} {\sc Multiscale Scattering for Audio Classifications}, {\em http://www.cmap.polytechnique.fr/scattering/ismir-final.pdf}
\bibitem{dl} {\sc Digital image processing: p067- Dictionary Learning}, {\em https://www.youtube.com/watch?v=XLXSVLKZE7U}
\bibitem{ipm} {\sc Interior-point methods}, {\em https://web.stanford.edu/class/ee364a/lectures/barrier.pdf}
\bibitem{ista} {\sc Iterative Shrinkage/Thresholding Algorithms}, {\em http://people.ee.duke.edu/~lcarin/figueiredo.pdf}
\bibitem{mpwtfd} {\sc Matching pursuits with time-frequency dictionaries}, {\em http://www.cmap.polytechnique.fr/~mallat/papiers/MallatPursuit93.pdf}
\bibitem{eik} {\sc Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit}, {\em http://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf}
\end{thebibliography}

\end{document}
